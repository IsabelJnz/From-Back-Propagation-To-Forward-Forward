# From-Back-Propagation-To-Forward-Forward
This paper presents an empirical investigation comparing Back Propagation and Forward-Forward, two algorithms for optimizing neural networks, using the MNIST data set. The study compared the algorithms based on their accuracy and found that the Forward-Forward algorithm outperforms Back Propagation. The results suggest a paradigm shift from Back Propagation to Forward-Forward in the optimization of neural networks, offering new insights into the field. The study highlights the superiority of the Forward-Forward algorithm and its potential to be adopted as the preferred optimization method.
